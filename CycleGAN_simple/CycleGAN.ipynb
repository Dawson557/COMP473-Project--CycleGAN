{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7wNjDKdQy35h"
   },
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##If you're curious about the GPU you've been assigned\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TRm-USlsHgEV"
   },
   "outputs": [],
   "source": [
    "####Only run this the first time!###\n",
    "#Subsequently, run the next block with pull command\n",
    "!git clone https://github.com/charlesabouhaidar/COMP473-Project.git\n",
    "import os\n",
    "os.chdir('COMP473-Project')\n",
    "os.chdir('CycleGAN_simple')\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This for sure doesn't work, you need to start the repo from the branch you're working on in the first place\n",
    "#!git checkout <branch_name>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pt3igws3eiVp"
   },
   "outputs": [],
   "source": [
    "## Update colab to reflect changes made to repo, Honestly not sure this works though.\n",
    "!git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8daqlgVhw29P"
   },
   "source": [
    "# Datasets\n",
    "Download one of the official datasets below (ordered by size, smallest to largest):\n",
    "<ul>\n",
    "    <li>grumpifycat</li>\n",
    "    <li>facades</li>\n",
    "    <li>apple2orange</li>\n",
    "    <li>horse2zebra</li>\n",
    "    <li>summer2winter_yosemite</li>\n",
    "    <li>cezanne2photo</li>\n",
    "    <li>ukiyoe2photo</li>\n",
    "    <li>monet2photo</li>\n",
    "    <li>vangogh2photo</li>\n",
    "    <li>iphone2dslr_flower</li>\n",
    "    <li>maps</li>\n",
    "   </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vrdOettJxaCc"
   },
   "outputs": [],
   "source": [
    "!bash ./datasets/download_cyclegan_datasets.sh vangogh2photo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yFw1kDQBx3LN"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that all training done on colab will not be saved. After running the training script below make sure to save the files locally on your computer using the appropriate cell-blocks in \"Save Checkpoints Locally\", to keep the results.\n",
    "<ul>\n",
    "    <li>--dataroot: the directory for the data you downloaded above</li>\n",
    "    <li>--name: the name you'd like to give your experiment</li>\n",
    "    <li>--n_epochs: The number of epochs to train without weight decay</li>\n",
    "    <li>--n_epochs_decay: The number of epochs to train with weight decay, these occur after n_epochs</li>\n",
    "    <li>There are more options for you to explore in options/base_options.py and option/train_options.py</li>\n",
    "   </ul>\n",
    "For experiment names I think it'd be helpful if we adopted the format dataset_name for example vangogh2photo_smalldiscriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0sp7TCT2x9dB"
   },
   "outputs": [],
   "source": [
    "!python train.py --dataroot ./datasets/summer2winter_yosemite --name <experiment_name> --n_epochs=40 --n_epochs_decay=40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue Training\n",
    "Make sure to upload the checkpoint files before running the next block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --dataroot ./datasets/vangogh2photo --name st!python train.py --dataroot ./datasets/summer2winter_yosemite --name summer2winter_medium_nets --model cycle_gan --display_id 0 --n_epochs=60 --n_epochs_decay=60 --netG=\"resnet_6blocks\" --continue_train --epoch_count=121"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Checkpoints Locally\n",
    "Google Colab is definitely a bit annoying for this part. We have to manually save the checkpoints and then push them to the repo for the next time, or upload them directly to colab for continued training later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##saving images from checkpoints takes too long and risks a time-out. Getting just the latest models seems best\n",
    "from google.colab import files\n",
    "files.download(\"model_checkpoints/vangogh2photo_cycleweight1/latest_net_D_A.pth\")\n",
    "files.download(\"model_checkpoints/vangogh2photo_cycleweight1/latest_net_D_B.pth\")\n",
    "files.download(\"model_checkpoints/vangogh2photo_cycleweight1/latest_net_G_A.pth\")\n",
    "files.download(\"model_checkpoints/vangogh2photo_cycleweight1/latest_net_G_B.pth\")\n",
    "files.download(\"model_checkpoints/vangogh2photo_cycleweight1/loss_log.txt\")\n",
    "files.download(\"model_checkpoints/vangogh2photo_cycleweight1/train_opt.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##this saves all the other model checkpoints but no images\n",
    "from google.colab import files\n",
    "!rm -r model_checkpoints/vangogh2photo_cycleweight1/web\n",
    "!zip -r model_checkpoints/vangogh2photo_cycleweight1.zip model_checkpoints/vangogh2photo_cycleweight1\n",
    "files.download(\"model_checkpoints/vangogh2photo_cycleweight1.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9UkcaFZiyASl"
   },
   "source": [
    "# Testing / Inference\n",
    "Same deal as training. To save the test results run the \"Save Results Locally\" right after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py --dataroot datasets/summer2winter_yosemite --name <experiment_name> --no_dropout --model cycle_gan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Results Locally\n",
    "Just change the <experiment_name\\> to match the same name you used while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r results/<experiment_name>.zip results/<experiment_name>/test_latest\n",
    "files.download(\"results/<experiment_name>_results.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Weight Increase on Cycle Loss (Short name: cycleweight)\n",
    "Defining feature of experiment:\n",
    "<p>Added a linear increase in the weight of the cycle consistency loss of main objective function. Where $k$ is the epoch number lambda was set accordingly. Extra hyperparameters for this experiment are $\\lambda_1$ and $c$.$$\\lambda_1 = 1.0, \\, \\lambda_k = \\min(1.0 + c*k, 20)$$</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:5px\">\n",
    "<h5> vangogh2photo_cycleweight1 Training Parameters</h5>\n",
    "<ul>\n",
    "<li>Dataset: vangogh2photo (6287 images)</li>\n",
    "    <li>Number of Epochs: 80</li>\n",
    "<li>Learning Rate: 0.0002</li>\n",
    "<li>batch size: 1</li>\n",
    "<li>image size: 128 x 128</li>\n",
    "<li>discriminators: 2 layer PatchGAN with 70 x 70 window</li>\n",
    "<li>generators: 6 block Residual Network </li>\n",
    "<li>pool size: 50</li>\n",
    "     <li>$\\lambda_1$: 1</li>\n",
    "    <li>$c$: 0.1</li>\n",
    "</ul>\n",
    "<i>***Training halted due to poor results at 80 epoch mark. Notice red artefacts in our result images below. We believe this is due to using too small a discriminator.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --dataroot ./datasets/vangogh2photo --name vangogh2photo_cycleweight1 --n_epochs=20 --n_epochs_decay=0 --cycle_weight=0.9 --cycle_weigth_inc=0.1 --save_latest_freq=125740 --save_epoch_freq=20 --print_freq=6287"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>vangogh2photo_cycleweight1 Training Losses</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '======'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-d83038877f31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mloss_to_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"vangogh2photo_cycleweight1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"report_resources/logs/vangogh2photo_cycleweight1_loss_log.txt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-cc02374c4ddf>\u001b[0m in \u001b[0;36mloss_to_graph\u001b[1;34m(experiment_name, path_to_loss_file)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m#Generator losses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m   \u001b[0mG_A\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mG_A_Loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m   \u001b[0mG_B\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mG_B_Loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;31m# Discriminator losses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '======'"
     ]
    }
   ],
   "source": [
    "loss_to_graph(\"vangogh2photo_cycleweight1\", \"report_resources/logs/vangogh2photo_cycleweight1_loss_log.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Inference Images</h5>\n",
    " <img src=\"report_resources/images/vangogh2photo_cycleweight1.png\" style=\"width:1000px;height:500px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:5px\">\n",
    "<h5> horse2zebra_cycleweight2 Training Parameters</h5>\n",
    "<ul>\n",
    "<li>Dataset: horse2zebra (1334 images)</li>\n",
    "    <li>Number of Epochs: 200, 100 without weight decay followed by 100 with weight decay to 0</li>\n",
    "<li>Learning Rate: 0.0002</li>\n",
    "<li>batch size: 1</li>\n",
    "<li>image size: 128 x 128</li>\n",
    "<li>discriminators: 3 layer PatchGAN with 70 x 70 window</li>\n",
    "<li>generators: 6 block Residual Network </li>\n",
    "<li>pool size: 50</li>\n",
    "     <li>$\\lambda_1$: 1</li>\n",
    "    <li>$c$: 0.1</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --dataroot ./datasets/horse2zebra --name horse2zebra_cycleweight2 --n_epochs=20 --n_epochs_decay=0 --cycle_weight=0.9 --cycle_weigth_inc=0.1 --save_latest_freq=125740 --save_epoch_freq=20 --print_freq=6287"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> horse2zebra_cycleweight2 Training Losses</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '======'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-6e8f90c003b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mloss_to_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"horse2zebra_cycleweight2\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"report_resources/logs/horse2zebra_cycleweight2_loss_log.txt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-cc02374c4ddf>\u001b[0m in \u001b[0;36mloss_to_graph\u001b[1;34m(experiment_name, path_to_loss_file)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m#Generator losses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m   \u001b[0mG_A\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mG_A_Loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m   \u001b[0mG_B\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mG_B_Loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;31m# Discriminator losses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '======'"
     ]
    }
   ],
   "source": [
    "loss_to_graph(\"horse2zebra_cycleweight2\", \"report_resources/logs/horse2zebra_cycleweight2_loss_log.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Inference Images</h5>\n",
    "Results from the paper are on the left with our results on the same images on the right. You can see that ours kept from changing the background colours as much and overall wasn't as zealous with adding strips to the images.<br>\n",
    "\n",
    " <img src=\"report_resources/images/horse2zebra_cycleweight2_1.png\" style=\"width:800px;height:200px\"/>\n",
    " <img src=\"report_resources/images/horse2zebra_cycleweight2_2.png\" style=\"width:800px;height:200px\"/>\n",
    " <img src=\"report_resources/images/horse2zebra_cycleweight2_3.png\" style=\"width:800px;height:200px\"/>\n",
    " <img src=\"report_resources/images/horse2zebra_cycleweight2_4.png\" style=\"width:800px;height:200px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:5px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Mgg8raPyizq"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_to_graph(experiment_name, path_to_loss_file):\n",
    "  counter = 1\n",
    "  G_A_Loss = []\n",
    "  G_B_Loss = []\n",
    "  D_A_Loss = []\n",
    "  D_B_Loss = []\n",
    "  Cycle_A = []\n",
    "  Cycle_B = []\n",
    "  idt_A = []\n",
    "  idt_B = []\n",
    "\n",
    "#line looks likes\n",
    "#(epoch: 9, iters: 2891, time: 0.371, data: 0.001) D_A: 0.123 G_A: 0.724 cycle_A: 1.047 idt_A: 0.401 D_B: 0.145 G_B: 0.715 cycle_B: 0.866 idt_B: 0.478\n",
    "  with open(path_to_loss_file) as fp:\n",
    "      for i, line in enumerate(fp):\n",
    "          if(i == 0):continue #skip first line of stats\n",
    "          position = line.find(\"G_A: \")\n",
    "          G_A_Loss.append(line[position+5 : position +11]) \n",
    "\n",
    "          position = line.find(\"G_B: \")\n",
    "          G_B_Loss.append(line[position+5 : position +11]) \n",
    "\n",
    "          position = line.find(\"D_A: \")\n",
    "          D_A_Loss.append(line[position+5 : position +11]) \n",
    "\n",
    "          position = line.find(\"D_B: \")\n",
    "          D_B_Loss.append(line[position+5 : position +11]) \n",
    "        \n",
    "          position = line.find(\"cycle_A: \")\n",
    "          Cycle_A.append(line[position+9 : position +15]) \n",
    "\n",
    "          position = line.find(\"cycle_B: \")\n",
    "          Cycle_B.append(line[position+9 : position +15])\n",
    "\n",
    "          position = line.find(\"idt_A: \")\n",
    "          idt_A.append(line[position+7 : position +13]) \n",
    "        \n",
    "          position = line.find(\"idt_B: \")\n",
    "          idt_B.append(line[position+7 : position +13]) \n",
    "\n",
    "          counter = counter +1\n",
    "\n",
    "#Generator losses\n",
    "  G_A = list(map(float, G_A_Loss))\n",
    "  G_B = list(map(float, G_B_Loss))\n",
    "# Discriminator losses  \n",
    "  D_A = list(map(float, D_A_Loss))\n",
    "  D_B = list(map(float, D_B_Loss))\n",
    "# Cycle consistency losses\n",
    "  C_A = list(map(float, Cycle_A)) \n",
    "  C_B = list(map(float, Cycle_B)) \n",
    "# Identity losses\n",
    "  ID_A = list(map(float, idt_A))\n",
    "  ID_B = list(map(float, idt_B))\n",
    "  experiment_name = \"Relative Discriminator\" ## LINE TO BE DELETED, WILL BE RECIEVIED AT THE TOP OF THE FUNCTION\n",
    "\n",
    "#x axis\n",
    "  x = list(range(1, len(G_A_Loss)+1))\n",
    "\n",
    "#y axis\n",
    "  fig = plt.figure(figsize=(16,20))\n",
    "  fig.suptitle(experiment_name)\n",
    "  ax1 = fig.add_subplot(311) ## generator plot\n",
    "  ax2 = fig.add_subplot(312) ## discriminator plot\n",
    "  ax3 = fig.add_subplot(313) ## Cycle consistency plot\n",
    "\n",
    "#Graph 1\n",
    "  ax1.set_title('Generators')\n",
    "  ax1.set_xlabel('epochs')\n",
    "  ax1.set_ylabel('error loss')\n",
    "  ax1.plot(x,G_A, color=\"blue\", label=\"Generator A\")\n",
    "  ax1.plot(x,G_B, color=\"red\", label=\"Generator B\")\n",
    "  ax1.legend()\n",
    "#Graph 2\n",
    "  ax2.set_title('Discriminators')\n",
    "  ax2.set_xlabel('epochs')\n",
    "  ax2.set_ylabel('error loss')\n",
    "  ax2.plot(x,D_A, color=\"blue\", label=\"Discriminator A\")\n",
    "  ax2.plot(x,D_B, color=\"red\", label=\"Discriminator B\")\n",
    "  ax2.legend()\n",
    "#Graph 3\n",
    "  ax3.set_title('Cycle losses')\n",
    "  ax3.set_xlabel('epochs')\n",
    "  ax3.set_ylabel('error loss')\n",
    "  ax3.plot(x,C_A, color=\"blue\", label=\"Cycle A\")\n",
    "  ax3.plot(x,C_B, color=\"red\", label=\"Cycle B\")\n",
    "  ax3.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "CycleGAN",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
